import numpy as np
import matplotlib.pyplot as plt

def gradient_descent(learning_rate, max_iterations, initial_x):
    x = initial_x
    x_history = []  
    for _ in range(max_iterations):
        gradient = 2 * (x + 3) 
        x = x - learning_rate * gradient  
        x_history.append(x)  

    return x, x_history


learning_rate = 0.1
max_iterations = 1000
initial_x = 2


local_minimum, x_history = gradient_descent(learning_rate, max_iterations, initial_x)

print(f"Local Minimum at x = {local_minimum}")


x_values = np.linspace(-10, 10, 400) 
y_values = (x_values + 3)**2  

plt.plot(x_values, y_values, label='y = (x + 3)^2', color='blue')
plt.scatter(x_history, [(x + 3)**2 for x in x_history], label='Gradient Descent Path', color='red', marker='x')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.title('Gradient Descent Convergence')
plt.grid(True)
plt.show()
print("Local Minimum at x = -2.999999999999999")